{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Importing all the required libraries.**",
   "id": "cf90c55c7f37d852"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T05:10:00.762807Z",
     "start_time": "2025-07-14T05:09:50.849670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "import yfinance as yf"
   ],
   "id": "7c1ee1c06fffa996",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Loading the news data and cleaning it.**",
   "id": "a56805179de80a3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T05:12:42.523266Z",
     "start_time": "2025-07-14T05:12:28.395763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#reading the news and cleaning the data\n",
    "news = pd.read_csv(\"news.csv\")\n",
    "news['date'] = pd.to_datetime(news['date'], errors='coerce', utc=True)\n",
    "news = news.dropna(subset=['date'])\n",
    "news['date'] = news['date'].dt.normalize()\n",
    "news['date'] = pd.to_datetime(news['date']).dt.tz_localize(None)\n",
    "\n",
    "\n",
    "#finding all unique tickers of stocks\n",
    "tickers = news['stock'].unique()"
   ],
   "id": "5db5f26f4c6dfe6f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Loading the financial data and mapping the news dates.**",
   "id": "e40cfaaf8316e074"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T06:16:57.922932Z",
     "start_time": "2025-07-14T06:16:57.900163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# news data for a particular stock.\n",
    "def particularNews(ticker):\n",
    "    news_data = news[news['stock'] == ticker]\n",
    "    news_data = news_data.iloc[::-1]\n",
    "    return news_data\n",
    "\n",
    "# stocks data for a particular stock.\n",
    "def particularStock(ticker):\n",
    "    stock_data = yf.download(tickers=ticker, start='2009-01-01', end='2020-07-31', interval='1d')\n",
    "    return stock_data\n",
    "\n",
    "# mapping the news dates to the next trading day as the effect will be on the next trading day.\n",
    "def mapDates(news_data, stock_data):\n",
    "    trading_days = pd.Series(stock_data.index)\n",
    "    calendar_days = pd.date_range(start=trading_days.min(), end=trading_days.max(), freq='D')\n",
    "\n",
    "    date_to_next_trading = {}\n",
    "\n",
    "    for date in calendar_days:\n",
    "        idx = trading_days.searchsorted(date, side='right')  # get strictly *next* trading day to test the returns for\n",
    "        if idx < len(trading_days):\n",
    "            date_to_next_trading[date] = trading_days.iloc[idx]\n",
    "        else:\n",
    "            date_to_next_trading[date] = pd.NaT\n",
    "\n",
    "    mapping_series = pd.Series(date_to_next_trading)\n",
    "\n",
    "    news_data['date'] = news_data['date'].map(mapping_series)\n",
    "\n",
    "    return news_data\n"
   ],
   "id": "9e7ba90046b7d687",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Caculating the sentiment of every news.**",
   "id": "4cdc54c8bf25c36e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:44:05.083696Z",
     "start_time": "2025-07-14T07:42:15.143040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mapSentiment(result):\n",
    "    if result['label'] == 'positive':\n",
    "            return 1\n",
    "    elif result['label'] == 'negative':\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "def sentimentAnalysis(news_data):\n",
    "    results = pipe(news_data['title'].tolist())\n",
    "    news_data['sentiment'] = [mapSentiment(r) for r in results]\n",
    "\n",
    "    return news_data\n",
    "\n",
    "news_data = particularNews('GOOGL')\n",
    "news_data = mapDates(news_data, particularStock('GOOGL'))\n",
    "news_data = sentimentAnalysis(news_data)\n"
   ],
   "id": "3737a574372775f4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achiv\\AppData\\Local\\Temp\\ipykernel_18524\\1974107285.py:9: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(tickers=ticker, start='2009-01-01', end='2020-07-31', interval='1d')\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Function for calculating the total CAGR.**",
   "id": "71e26fcd9b56e971"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:44:05.364896Z",
     "start_time": "2025-07-14T07:44:05.131987Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achiv\\AppData\\Local\\Temp\\ipykernel_18524\\1974107285.py:9: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(tickers=ticker, start='2009-01-01', end='2020-07-31', interval='1d')\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  sentiment\n",
      "0   2018-07-26          0\n",
      "1   2018-07-27          0\n",
      "2   2018-07-30          0\n",
      "3   2018-07-31          0\n",
      "4   2018-08-01          1\n",
      "..         ...        ...\n",
      "423 2020-06-05          0\n",
      "424 2020-06-08          0\n",
      "425 2020-06-09          0\n",
      "426 2020-06-10          0\n",
      "427 2020-06-11          0\n",
      "\n",
      "[428 rows x 2 columns]\n",
      "            Close_GOOGL  High_GOOGL  Low_GOOGL  Open_GOOGL  Volume_GOOGL  \\\n",
      "Date                                                                       \n",
      "2009-01-02     7.993104    8.005542   7.599568    7.676683     144275580   \n",
      "2009-01-05     8.160518    8.239872   7.835888    7.985144     195364440   \n",
      "2009-01-06     8.310021    8.477685   8.119223    8.283155     256750992   \n",
      "2009-01-07     8.010266    8.231661   7.929172    8.167233     179600220   \n",
      "2009-01-08     8.089374    8.089374   7.894098    7.917481     143883972   \n",
      "...                 ...         ...        ...         ...           ...   \n",
      "2020-07-24    74.960938   75.319785  73.936086   74.512630      29902000   \n",
      "2020-07-27    76.015602   76.419680  75.165704   75.211927      27124000   \n",
      "2020-07-28    74.734291   75.845622  74.578722   75.795424      30910000   \n",
      "2020-07-29    75.721367   76.209437  74.702476   74.801385      22676000   \n",
      "2020-07-30    76.459953   76.585202  74.312827   74.451991      36042000   \n",
      "\n",
      "             return_  \n",
      "Date                  \n",
      "2009-01-02 -0.041218  \n",
      "2009-01-05 -0.021963  \n",
      "2009-01-06 -0.003243  \n",
      "2009-01-07  0.019219  \n",
      "2009-01-08 -0.021710  \n",
      "...              ...  \n",
      "2020-07-24 -0.006017  \n",
      "2020-07-27 -0.010685  \n",
      "2020-07-28  0.014000  \n",
      "2020-07-29 -0.012299  \n",
      "2020-07-30 -0.026970  \n",
      "\n",
      "[2914 rows x 6 columns]\n",
      "         Date     returns\n",
      "0  2018-08-01  100.493902\n",
      "1  2018-08-29  101.266622\n",
      "2  2018-08-30  101.984799\n",
      "3  2018-09-06  100.744205\n",
      "4  2018-09-26  100.712982\n",
      "..        ...         ...\n",
      "82 2020-04-30  106.640699\n",
      "83 2020-05-08  106.446221\n",
      "84 2020-05-27  106.425232\n",
      "85 2020-05-29  107.406000\n",
      "86 2020-06-01  108.096822\n",
      "\n",
      "[87 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108.09682176135465"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57,
   "source": [
    "def classify(score):\n",
    "    if score >= 2: return 1\n",
    "    elif score <= -2: return -1\n",
    "    else: return 0\n",
    "\n",
    "def CAGR(ticker):\n",
    "    # news_data = particularNews(ticker)\n",
    "    stock_data = particularStock(ticker)\n",
    "    if stock_data.empty:\n",
    "        return \"why\"\n",
    "    # news_data = mapDates(news_data, stock_data)\n",
    "    # news_data = sentimentAnalysis(news_data)\n",
    "\n",
    "    date_sentiment = news_data.groupby('date')['sentiment'].sum()\n",
    "    date_sentiment = date_sentiment.apply(classify).reset_index()\n",
    "    # print((date_sentiment[0]))\n",
    "\n",
    "    starting_amount = 100\n",
    "\n",
    "    stock_data['return'] = ((stock_data['Open']-stock_data['Close'])/stock_data['Open'])\n",
    "\n",
    "    stock_data.columns = ['_'.join(col) for col in stock_data.columns.to_flat_index()]\n",
    "    date_sentiment.rename(columns={'date':'Date'}, inplace = True)\n",
    "    print(date_sentiment)\n",
    "    print(stock_data)\n",
    "    data = pd.merge(date_sentiment, stock_data, on='Date')\n",
    "\n",
    "    # print(data)\n",
    "    trade_data = pd.DataFrame({})\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        if row['sentiment'] == -1:\n",
    "            starting_amount *= -1*(-1 + row['return_'])\n",
    "            new_row = {'Date': row['Date'], 'returns': starting_amount}\n",
    "            trade_data = pd.concat([trade_data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        elif row['sentiment'] == 1 :\n",
    "            starting_amount *= (1 + row['return_'])\n",
    "            new_row = {'Date': row['Date'], 'returns': starting_amount}\n",
    "            trade_data = pd.concat([trade_data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "\n",
    "    print(trade_data)\n",
    "    return starting_amount\n",
    "\n",
    "# everything = pd.DataFrame({})\n",
    "#\n",
    "# tickers = {\"NVDA\", \"MSFT\", \"AAPL\", \"AMZN\", \"META\",\"\tAVGO\",\"GOOGL\",\"\tGOOG\",\"NFLX\",\"\tCOST\"}\n",
    "#\n",
    "# for ticker in tickers:\n",
    "#     returns = CAGR(ticker)\n",
    "#     if returns == 'why':\n",
    "#         new_row = {\"stock\": ticker, \"return\": 'no data'}\n",
    "#         everything = pd.concat([everything, pd.DataFrame([new_row])], ignore_index=True)\n",
    "#         continue\n",
    "#     new_row = {\"stock\": ticker, \"return\": returns}\n",
    "#     everything = pd.concat([everything, pd.DataFrame([new_row])], ignore_index=True)\n",
    "#\n",
    "# everything\n",
    "CAGR('GOOGL')\n"
   ],
   "id": "e19a526c73b9b525"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
