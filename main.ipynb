{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Importing all the required libraries.**",
   "id": "cf90c55c7f37d852"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T06:17:31.867945Z",
     "start_time": "2025-07-15T06:17:17.407899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)"
   ],
   "id": "7c1ee1c06fffa996",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Loading the news data and cleaning it.**",
   "id": "a56805179de80a3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:44:34.925513Z",
     "start_time": "2025-07-15T17:44:21.132739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#reading the news and cleaning the data\n",
    "news = pd.read_csv(\"data/news.csv\")\n",
    "news['date'] = pd.to_datetime(news['date'], errors='coerce', utc=True)\n",
    "news = news.dropna(subset=['date'])\n",
    "news['date'] = news['date'].dt.normalize()\n",
    "news['date'] = pd.to_datetime(news['date']).dt.tz_localize(None)\n",
    "\n",
    "\n",
    "#finding all unique tickers of stocks\n",
    "tickers = news['stock'].unique()"
   ],
   "id": "5db5f26f4c6dfe6f",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Loading the financial data and mapping the news dates.**",
   "id": "e40cfaaf8316e074"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T06:17:48.013528Z",
     "start_time": "2025-07-15T06:17:47.996440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#dates\n",
    "start_date = '2009-01-01'\n",
    "end_date = '2020-07-31'\n",
    "\n",
    "# news data for a particular stock.\n",
    "def particularNews(ticker):\n",
    "    news_data = news[news['stock'] == ticker]\n",
    "    news_data = news_data.iloc[::-1]\n",
    "    return news_data\n",
    "\n",
    "# stocks data for a particular stock.\n",
    "def particularStock(ticker):\n",
    "    stock_data = yf.download(tickers=ticker, start= start_date, end=end_date, interval='1d')\n",
    "    return stock_data\n",
    "\n",
    "# mapping the news dates to the next trading day as the effect will be on the next trading day.\n",
    "def mapDates(news_data, stock_data):\n",
    "    trading_days = pd.Series(stock_data.index)\n",
    "    calendar_days = pd.date_range(start=trading_days.min(), end=trading_days.max(), freq='D')\n",
    "\n",
    "    date_to_next_trading = {}\n",
    "\n",
    "    for date in calendar_days:\n",
    "        idx = trading_days.searchsorted(date, side='right')  # get strictly *next* trading day to test the returns for\n",
    "        if idx < len(trading_days):\n",
    "            date_to_next_trading[date] = trading_days.iloc[idx]\n",
    "        else:\n",
    "            date_to_next_trading[date] = pd.NaT\n",
    "\n",
    "    mapping_series = pd.Series(date_to_next_trading)\n",
    "\n",
    "    news_data['date'] = news_data['date'].map(mapping_series)\n",
    "\n",
    "    return news_data\n"
   ],
   "id": "9e7ba90046b7d687",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Caculating the sentiment of every news.**",
   "id": "4cdc54c8bf25c36e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:50:54.121537Z",
     "start_time": "2025-07-15T08:50:54.101373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mapSentiment(result):\n",
    "    if result['label'] == 'positive':\n",
    "            return 1\n",
    "    elif result['label'] == 'negative':\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "def sentimentAnalysis(news_data):\n",
    "    results = pipe(news_data['title'].tolist())\n",
    "    news_data['sentiment'] = [mapSentiment(r) for r in results]\n",
    "\n",
    "    return news_data\n",
    "\n",
    "\n",
    "def totalNews(ticker, stock_data = 'nothing'):\n",
    "    news_data = particularNews(ticker)\n",
    "    # news_data = mapDates(news_data, particularStock(ticker))\n",
    "    news_data = mapDates(news_data, stock_data)\n",
    "    news_data = sentimentAnalysis(news_data)\n",
    "    return news_data\n",
    "\n",
    "# news_data = totalNews('AVGO')"
   ],
   "id": "3737a574372775f4",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Function for calculating the total CAGR.**",
   "id": "71e26fcd9b56e971"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:35:46.572121Z",
     "start_time": "2025-07-15T17:35:44.093570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate(data, ticker):\n",
    "    money = 100\n",
    "    # trade_data = pd.DataFrame({})\n",
    "\n",
    "    # standing_trade = False\n",
    "    # amount = 0\n",
    "\n",
    "    # row[f'Open_{ticker}'] < row['EMA_']\n",
    "\n",
    "    i = 0\n",
    "    invested = True\n",
    "    last_price = data.iloc[0][f'Open_{ticker}']\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        if i == 3:\n",
    "            last_price = row[f'Open_{ticker}']\n",
    "            invested = True\n",
    "\n",
    "        if row['sentiment'] == -1 and row[f'5MA_'] < row['20MA_'] and invested:\n",
    "            # money *= row[f'Open_{ticker}']/last_price\n",
    "            # last_price = row[f'Close_{ticker}']\n",
    "            if invested:\n",
    "                invested = False\n",
    "                money *= row[f'Open_{ticker}']/last_price\n",
    "                i = 0\n",
    "            else:\n",
    "                i = 0\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    if invested:\n",
    "        money *= data.iloc[-1][f'Close_{ticker}']/last_price\n",
    "\n",
    "\n",
    "    # data analysis\n",
    "    number_of_years = (data['Date'].max() - data['Date'].min()).days / 365\n",
    "    cagr = (((money/100)**(1/number_of_years)) -1 ) * 100\n",
    "    simple_cagr = (((data.iloc[-1][f'Close_{ticker}']/data.iloc[0][f'Close_{ticker}'])**(1/number_of_years)) -1) * 100\n",
    "\n",
    "    rtrn = pd.DataFrame({\"CAGR using strategy\": cagr, \"CAGR without strategy\": simple_cagr, \"Company\": ticker, \"Number of years\": number_of_years}, index=[0])\n",
    "\n",
    "    return rtrn\n",
    "\n",
    "\n",
    "# configuring data\n",
    "def config(data, ticker):\n",
    "    # Data date and time configurations\n",
    "    data['Date'] = pd.to_datetime(data['Date'], errors='coerce', utc=True)\n",
    "    data = data.dropna(subset=['Date'])\n",
    "    data['Date'] = data['Date'].dt.normalize()\n",
    "    data['Date'] = pd.to_datetime(data['Date']).dt.tz_localize(None)\n",
    "\n",
    "\n",
    "    data['20MA_'] = data[f'Close_{ticker}'].ewm(span = 20, adjust=False, min_periods=1).mean()\n",
    "    data['20MA_'] = data['20MA_'].shift(-1)\n",
    "    data['5MA_'] = data[f'Close_{ticker}'].ewm(span = 5, adjust=False, min_periods=1).mean()\n",
    "    data['5MA_'] = data['5MA_'].shift(-1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# this means that sentiment is should be really negative\n",
    "def classify(score):\n",
    "    if score >= 2: return 1\n",
    "    elif score <= -2: return -1\n",
    "    else: return 0\n",
    "\n",
    "\n",
    "def CAGR(ticker):\n",
    "    stock_data = particularStock(ticker)\n",
    "    news_data = totalNews(ticker, stock_data)\n",
    "\n",
    "    # if no stock data on yfinance\n",
    "    if stock_data.empty: return \"why\"\n",
    "\n",
    "    # aggregate sentiment for a particular date\n",
    "    date_sentiment = news_data.groupby('date')['sentiment'].sum()\n",
    "    date_sentiment = date_sentiment.apply(classify).reset_index()\n",
    "\n",
    "    # rolling average\n",
    "    stock_data['return'] = ((stock_data['Open']-stock_data['Close'])/stock_data['Open'])\n",
    "    stock_data['EMA'] = stock_data['Close'].rolling(window=20).mean()\n",
    "\n",
    "    # just flattening the data\n",
    "    stock_data.columns = ['_'.join(col) for col in stock_data.columns.to_flat_index()]\n",
    "    date_sentiment.rename(columns={'date':'Date'}, inplace = True)\n",
    "\n",
    "    # union of news and stock data\n",
    "    data = pd.merge(date_sentiment, stock_data, on='Date', how='outer')\n",
    "\n",
    "    # data = pd.read_csv(f'data/{ticker}_data.csv')\n",
    "\n",
    "    data = config(data, ticker)\n",
    "\n",
    "    return calculate(data, ticker)\n",
    "\n",
    "\n",
    "# companies with the largest market cap and at least 10 years of news data\n",
    "companies = pd.read_csv('data/companies.csv')\n",
    "returns = pd.DataFrame()\n",
    "\n",
    "for _,company in companies.iterrows():\n",
    "    rtrn = CAGR(company['Symbol'])\n",
    "    returns = pd.concat([returns, rtrn], ignore_index=True)\n",
    "\n",
    "print(returns)"
   ],
   "id": "e19a526c73b9b525",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CAGR using strategy  CAGR without strategy Company  Number of years\n",
      "0            39.678748              33.639455    AVGO        10.989041\n",
      "1            27.640487              26.269882     TSM        11.580822\n",
      "2            15.123622              16.240333     LLY        11.580822\n",
      "3            32.865049              30.520303      MA        11.580822\n",
      "4            23.746840              26.132495      HD        11.580822\n",
      "5            33.992310              33.398024    ASML        11.580822\n",
      "6            19.753022              19.672491     NVO        11.580822\n",
      "7            10.530753               9.883191      KO        11.580822\n",
      "8             9.398106               9.792891     NVS        11.580822\n",
      "9             5.771306              11.471818      MS        11.580822\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Testing Code.**",
   "id": "98ffe26328e1339e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:40:24.423351Z",
     "start_time": "2025-07-15T17:40:24.403868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# starting_amount *= row[f'Open_{ticker}']/amount\n",
    "            # new_row = {'Date': row['Date'], 'returns': starting_amount}\n",
    "            # trade_data = pd.concat([trade_data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        # if row['sentiment'] == 1 and row[f'Open_{ticker}'] > row['EMA_']:\n",
    "        #     starting_amount *= (1 + row['return_'])\n",
    "            # standing_trade = True\n",
    "            # amount = row[f'Open_{ticker}']\n",
    "            # new_row = {'Date': row['Date'], 'returns': starting_amount}\n",
    "            # trade_data = pd.concat([trade_data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    #closing any standing trades\n",
    "    # if standing_trade:\n",
    "    #     starting_amount *= data.iloc[-1][f'Close_{ticker}']/amount\n",
    "# returns.to_csv(\"returns.csv\", index=False)"
   ],
   "id": "e0efec82532589b8",
   "outputs": [],
   "execution_count": 99
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
